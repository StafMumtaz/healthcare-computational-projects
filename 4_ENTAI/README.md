# ENTAI Overview

This is an example of code use in my most recent work. 
This project shows gathering and analyzing data for a meta analysis on attemps to use Natural Language Processing (NLP) in the field of Otolaryngology. 

`1_Initial Selection` contains the first set of **python** scripts and **Claude** API calling to automate the process of filtering out 100 papers from a ~180 paper sample. 
`2_Scaled Analysis` contains a more ambitious use of **GPT4.1** API, showing how it will scan ~3000 papers in the field, generating numerical insights.

##More on Associated Paper

I want to characterize where natural langauge processing is being used in actual clinical practice. 
A large chunk of academic research in the field of this research question are forms of testing LLM knowledge and output quality. 
I wanted to find uses of its actual application in clinical settings, or aiding basic sciences research, and see if there are areas where it seems to be generating real utility. 
Early analysis seems to reveal it is being used to generate new insights from looking at large datasets, work that would otherwise not be done. Rates of error persist as a bottleneck against use in clinical settings, not many researchers that are published yet in the medical field seem to have sophisticated scaffolding to enhance outputs or complement integration. 

**Some Notes**
- This was self directed, but much of the code is directly generated by Claude 4.0 Opus and ChatGPT O3, more so than previous works due to increases in AI utility. 
- Large datasets were redacted from `2_Scaled Analysis` due to memory contraints in GitHub. 
- API Keys are redacted. 
- Final Python script in `2_Scaled Analysis` shows a limit on the API usage to the first 5 studies in the dataset, a trial run before deploying to all 3000 studies. 

